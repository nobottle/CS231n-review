# CS231n Lec2. Image Classification

컴퓨터 비전에서 이미지 분류작업은 중요하다.

이미지 분류란..? >>어떤 사진들을 보았을 때 그 사진들이 어떤 물체 or 동물 등인지 분류하는 것

ex)

![스크린샷 2023-03-07 오전 1.09.59.png](CS231n%20Lec2%20Image%20Classification%20cba20670d7c7424f9936d58df3a56f9e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_1.09.59.png)

이런거를 고양이다!라고 분류하는것

사람을 쉽지만 컴퓨터는 쉽지 않다. 컴퓨터는 사진을 볼 때 수없이 많은 숫자들의 나열로 본다

![스크린샷 2023-03-07 오전 1.11.12.png](CS231n%20Lec2%20Image%20Classification%20cba20670d7c7424f9936d58df3a56f9e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_1.11.12.png)

이런식으로… 픽셀을 의미하는 숫자 집합으로 본다고 할 수 있다. 이 픽셀값은

1. Viewpoint variation(카메라의 위치 변화)
2. Illumination(조명에 의한 변화)
3. Deformation(객체 변형에 의한 변화)
4. Occlusion(객체 가려짐에 의한 변화)
5. Background Clutter(배경과 유사한 색의 경계)
6. IntraClass variation(클래스 내부의 분산)

이렇게 다양한 경우에 따라 달라진다 이럴 경우 분류를 하기 어렵다…

그렇다면 다양한 변수에도 분류를 할 수 있는 방법은 무엇일까?

**Image Classification Algorithm**

두 가지가 있다

1.feature을 찾고,feature을 이용하여 명시적인 규칙을 만듬(사람이 인위적으로 feature을 추출,규칙을 생성)

단점은 다른이미지에 적용이 어렵,,,

2.데이터 중심으로 접근(data-driven approach)

이미지와 라벨 데이터셋 수집

분류기를 학습하는데 머신러닝 이용

새로운 이미지를 사용해 분류기를 평가

>>함수를 잘 만들어야 함! 이미지를 넣으면 특징을 추출하여 분류할 대상에 대한 확률값을 계산하는 형식

K-Nearest neighbor Algorithm

K-Nearest Neighbor Algorithm은 분류 알고리즘으로써 새로운 데이터가 들어왔을 때 어떻게 분류를 할 것인가를 정해주는 알고리즘이다

K-NN알고리즘이라고도 불리는데 이거는 두 가지 과정을 거침

train과정과 predict과정

train과정 : 모든 train data를 기억

predict과정 : 입력 데이터를 train data와 비교하여 어떤 label값을 가질지 예측

이미지 분류에서는 K-Nearest Neighbor Algorithm을 잘 사용하지 않는다

Distance Metric(거리 척도)
L1 Distance(Manhattan distance), L2 Distance(Euclidean distance)

![스크린샷 2023-03-07 오전 1.58.21.png](CS231n%20Lec2%20Image%20Classification%20cba20670d7c7424f9936d58df3a56f9e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_1.58.21.png)

특정 벡터가 개별적인 의미를 가지고 있다면(키나 몸무게) L1 distance를,일반적인 벡터 요소들의 의미를 모르거나 별로 없을 경우 L2 distance를 사용

**Hyper Parameter**

학습을 하는데 영향을 미치는 parameter이면서, 학습을 통해 알아내기 보다는 학습을 하기 전 선택하는 parameter를 하이퍼파라미터라고 한다. (ex. K값, Distance Metric)

이 하이퍼파라미터를 잘 선택하려면

1.데이터에 맞게 다양한 값을 시도해보고 가장 좋은 값을 찾는 법

2.Dataset을 Train, val, test 로 나누어 한번도 보지 못한 data에 대해 분류를 잘 하게 되는 하이퍼파라미터를 선정

정리하자면…

다양한 Classification Algorithm 들이 정확한 분류값을 도출하기 위해 결과 값에 영향을 미치는 값을 **HyperParameter라고 함**

다양한 방법들이 있다. 그 중 

1.Dataset에서 train,val,test로 나누는 방법.

2교차 검증(cross-validation)방법 (딥러닝에서는 잘 사용하지 않음),시간이 오래걸림

![스크린샷 2023-03-07 오전 1.18.09.png](CS231n%20Lec2%20Image%20Classification%20cba20670d7c7424f9936d58df3a56f9e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_1.18.09.png)

이미지 분류에서는 kNN사용을 안함

1.시간이 오래걸림

2.distance metric는 픽셀 단위에서는 별로…?

벡터 간의 거리 측정 관련 함수(L1,L2)들은 이미지들 간의 ‘시각적 유사성’을 측정하는 척도로 적절하지 않다.

다음 이미지들 간 L2 distance를 측정했을 때 모두 같다.

![스크린샷 2023-03-07 오전 2.02.15.png](CS231n%20Lec2%20Image%20Classification%20cba20670d7c7424f9936d58df3a56f9e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_2.02.15.png)

3.차원이 늘어나면 train data개 많아짐…

K-NN이 잘 작동하려면 고차원 공간을 모두 커버할 정도로 많은 데이터가 필요한데 차원의 수가 늘어날 수록 그렇게 많은 데이터를 모으는 것은 현실적으로 불가능하다.

**Linear Classification**

parametric model의 가장 단순한 형태

parametric model이란…?

데이터가 특정 분포를 따른다고 가정,우리가 학습을 하면서 결정해야 하는 파라미터의 종류와 수가 명확하게 정해져 있다 > 데이터가 많은 결정해야 할 파라미터의 수는 변하지 x

우선 모델의 형태를 정하고,이 모델의 파라미터를 학습을 통해 발전시켜나가는 식

inear regression, Logistic Regression, Neural Network 등, 모델이 학습해야 하는 것이 명확히 정해져 있기 때문에 속도가 빠르고, 모델을 이해하기가 쉽다는 장점이 있다.하지만 속도가 느린 경우가 많고, 더 큰 데이터를 필요로 하는 경우가 있으며 모델이 왜 그런 형태가 되었는지에 대한 명확한 설명을 하기가 쉽지 않다.

Non-Parametric model이란…?

데이터가 특정 분포를 따른다는 가정이 없음 우리가 학습에 따라 튜닝해야 할 파라미터가 명확하게 정해져 있지 않은 것→ data에 대한 사전 지식이 전혀 없을 때 유용하게 사용될 수 있다.

Decision tree, Random forest, K-nearest neighbor classifier 등, 데이터가 특정한 분포를 따른다는 가정을 하지 않기 때문에 더 flexible하다는 장점이 있다. 하지만 속도가 느린 경우가 많고, 더 큰 데이터를 필요로 하는 경우가 있으며 모델이 왜 그런 형태가 되었는지에 대한 명확한 설명을 하기가 쉽지 않다

![스크린샷 2023-03-07 오전 2.06.21.png](CS231n%20Lec2%20Image%20Classification%20cba20670d7c7424f9936d58df3a56f9e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_2.06.21.png)

여기서

x:input image

w:가중치

b:bias 

f(x,W) = Wx + b는 Linear Classification

이미지 데이터,가중치 값을 더해 각 10개의 Class에 대한 점수를 나타냄

train을 하며 w에 적절한 가중치 값을 모아줌

이 학습된 가중치를 통해 낮은 성능의 기기에서도 새로운 데이터에 대한 predict을 빠르게 진행할 수 잇음

![스크린샷 2023-03-07 오전 2.08.11.png](CS231n%20Lec2%20Image%20Classification%20cba20670d7c7424f9936d58df3a56f9e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_2.08.11.png)

Linear Classifier의 다른 관점 : 이미지를 고차원 공간의 한 점으로 생각

각 이미지를 고차원 공간의 한 점이라고 할때  Linear Classifier는 각 클래스를 구분시켜주는 선형 결정 경계를 그어주는 역할 아래와 같이 생각하면 됨

![스크린샷 2023-03-07 오전 2.09.22.png](CS231n%20Lec2%20Image%20Classification%20cba20670d7c7424f9936d58df3a56f9e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_2.09.22.png)

이것들이 사용이 어려운 경우는

![스크린샷 2023-03-07 오전 2.09.45.png](CS231n%20Lec2%20Image%20Classification%20cba20670d7c7424f9936d58df3a56f9e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_2.09.45.png)

영역이 반전되어 있거나, 한 클래스가 다양한 공간에 분포하면 그렇다