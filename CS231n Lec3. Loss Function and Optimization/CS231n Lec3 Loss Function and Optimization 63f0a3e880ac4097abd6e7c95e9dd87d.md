# CS231n Lec3. Loss Function and Optimization

**Multiclass Support Vector Machine Loss(Multiclass SVM loss)**

loss function은 모델이 나타내는 확률분포와 데이터가 따르는 실제 확률 분포 사이의 차이를 나타내는 함수

![스크린샷 2023-03-07 오전 3.23.28.png](CS231n%20Lec3%20Loss%20Function%20and%20Optimization%2063f0a3e880ac4097abd6e7c95e9dd87d/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_3.23.28.png)

이거를 보았을 때 안맞는 결과가 보인다

여기서 w값은 최아인 것이다

이 w가 좋다 안좋다라고 정량화 할 수 잇는 것이 필요한데 이를 loss function이라고 한다

즉 loss function은 실제값과 예측값의 차이를 수치화 해주는 함수이다

w가 좋은가? 안좋은가?를 정량화 해주는 역할!!

클수록 Loss function값이 크고,오차가 작을수록 loss function의 값이 작아진다

이 loss function의 값을 최소화 하는 w,b를 찾아가는 것이 최적화과정 이라고 한다

최적화 과정은 optimization이라고 한다

![스크린샷 2023-03-07 오전 3.34.02.png](CS231n%20Lec3%20Loss%20Function%20and%20Optimization%2063f0a3e880ac4097abd6e7c95e9dd87d/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_3.34.02.png)

x는 이미지 y는 카테고리(라벨값)이다

라벨값이라는 것은 위에서는 고양이는0,자동차는1,개구리는2

i는 카테코리별(0,1,2) loss를 각각 구한다

그리고 더한다

마지막으로 개수로 나눠 평균값을 만든다

이게 최종 loss!

![스크린샷 2023-03-07 오전 3.36.01.png](CS231n%20Lec3%20Loss%20Function%20and%20Optimization%2063f0a3e880ac4097abd6e7c95e9dd87d/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_3.36.01.png)

여기서는 서포트 벡터 머신(SVM)loss다

hinge loss라고도 불리운다

근데 위와 다르게 if문 조건이 있다

여기서 sj는 클래스 score고

syi는 정답 클래스 score이다

즉 조건을 정리하면

만약 정답 클래스가 정답이 아닌 클래스 + safety margin값보다 더 크면 loss는 0

위 조건이 아니면 정답이 아닌 클래스-정답클래스_safety marjin의 값을 loss로 가진다는 뜻

정리하면 정답 클래스가 정답이 아닌 클래스+ safety margin보다 크면 loss는 0

loss가 0이면 좋다는 거다 

![스크린샷 2023-03-07 오전 3.40.30.png](CS231n%20Lec3%20Loss%20Function%20and%20Optimization%2063f0a3e880ac4097abd6e7c95e9dd87d/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_3.40.30.png)

그래프는 이런 형태다

식으로 표현하자면

![스크린샷 2023-03-07 오전 3.40.57.png](CS231n%20Lec3%20Loss%20Function%20and%20Optimization%2063f0a3e880ac4097abd6e7c95e9dd87d/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_3.40.57.png)

이런식이 된다

예를들어보자 아래를 보면

![스크린샷 2023-03-07 오전 3.41.25.png](CS231n%20Lec3%20Loss%20Function%20and%20Optimization%2063f0a3e880ac4097abd6e7c95e9dd87d/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_3.41.25.png)

고양이는 정답 클래스

근데 자동차 score가 5.1로 고양이 보다 높다

당연 Loss가 잇을것!

오른쪽 파란네모 식대로 해서 Loss를 구한다

개구리하고 해보면 loss는 0이 나옴

다시 자동차하고의 Loss를 구해보면 2.9가 나오는데

이거는 2.9만큼 안좋다는 뜻으로 기억해두자

이 방식으로 loss를 다 구해보면

![스크린샷 2023-03-07 오전 3.50.20.png](CS231n%20Lec3%20Loss%20Function%20and%20Optimization%2063f0a3e880ac4097abd6e7c95e9dd87d/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_3.50.20.png)

이런식이다 5.27은 최종loss

이 svm hinge loss는 데이터에 민감하지 않음 둔감. 정답 클래스가 다른 클래스보다 높은지만 관심

질문사항:

1.잘 예측했을 경우 syi값이 미세하게 바뀐다고 해서 loss값은 바뀌지 않음

2.Loss최소값은 0 (제일 좋은거) 최대값은 무한대일거

3.만약 sum대신 평균을 하면? 단지 scale만 작아진다

그러나 우리는 Loss에만 관심

4.제곱승을 하면…?

![스크린샷 2023-03-07 오후 1.12.54.png](CS231n%20Lec3%20Loss%20Function%20and%20Optimization%2063f0a3e880ac4097abd6e7c95e9dd87d/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.12.54.png)

값이 non linear하게 됨 이거를 squared hinge loss라고도 불린다

때에 따라선 잘 먹혀둠 곡선으로 제곱승으로 올라가기 때문

일반적으로는 사용하지 않음

![스크린샷 2023-03-07 오후 1.16.41.png](CS231n%20Lec3%20Loss%20Function%20and%20Optimization%2063f0a3e880ac4097abd6e7c95e9dd87d/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.16.41.png)

위 코드를 넘파이로 바꾼거는 아래와 같다

![스크린샷 2023-03-07 오후 1.17.25.png](CS231n%20Lec3%20Loss%20Function%20and%20Optimization%2063f0a3e880ac4097abd6e7c95e9dd87d/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.17.25.png)

주의할거는 우리는 새로운 값에  예측을 하고싶다

test data에 관심을 갖는다

그러나 위의 과정은 train set에서 하고 맞춘거

즉 w값은 train set에 맞춰져 있음

과연 test set에도 이가 맞을까…?

안 맞을 가능성이 농후함

![스크린샷 2023-03-07 오후 1.21.41.png](CS231n%20Lec3%20Loss%20Function%20and%20Optimization%2063f0a3e880ac4097abd6e7c95e9dd87d/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.21.41.png)

초록색이 test인데 이러면 예측을 할 수가 없다

이거를 오버피팅이라고 한다(훈련데이터에 너무 맞춰져 있어 테스트때는 효과가 안나타나는 것)

![스크린샷 2023-03-07 오후 1.22.32.png](CS231n%20Lec3%20Loss%20Function%20and%20Optimization%2063f0a3e880ac4097abd6e7c95e9dd87d/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.22.32.png)

이 초록색 모양이면 된다 test에도 맞는 w값을 찾아야 한다는 것

여기서 regulariztion이 나온다

![스크린샷 2023-03-07 오후 1.24.56.png](CS231n%20Lec3%20Loss%20Function%20and%20Optimization%2063f0a3e880ac4097abd6e7c95e9dd87d/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.24.56.png)

data loss는 train data에 맞춘거다

문제를 해결하기 위해 R(w)를 추가

R(w):

L1,L2 regulariztion이 있다

L1 : 작은 가중치는 0으로 수렴 >>의미있는 가중치만 결국 남게 됨

L2:가중치를 0에 가깝도록 유도,모든 데이터 값들을 고려

/\:높으면 모델이 단순,낮으면 복잡해짐

**softmax**

score을 전부 이용,이거를 거치면 확률 분포를 얻고 확률로 표현됨

0,1사이의 값이고 확률들의 합은 1이 된다

![스크린샷 2023-03-07 오후 1.47.21.png](CS231n%20Lec3%20Loss%20Function%20and%20Optimization%2063f0a3e880ac4097abd6e7c95e9dd87d/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.47.21.png)

![스크린샷 2023-03-07 오후 1.47.52.png](CS231n%20Lec3%20Loss%20Function%20and%20Optimization%2063f0a3e880ac4097abd6e7c95e9dd87d/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.47.52.png)

![스크린샷 2023-03-07 오후 1.48.06.png](CS231n%20Lec3%20Loss%20Function%20and%20Optimization%2063f0a3e880ac4097abd6e7c95e9dd87d/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.48.06.png)

마지막에 log를 취하는데…

![스크린샷 2023-03-07 오후 1.49.16.png](CS231n%20Lec3%20Loss%20Function%20and%20Optimization%2063f0a3e880ac4097abd6e7c95e9dd87d/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.49.16.png)

보면 x축 확룰,y축이 loss라고 한다면 빨간색을 보았을 때

확률자체가 1에 가까워지면 Y즉 loss값을 0으로 가는중

![스크린샷 2023-03-07 오후 1.51.54.png](CS231n%20Lec3%20Loss%20Function%20and%20Optimization%2063f0a3e880ac4097abd6e7c95e9dd87d/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.51.54.png)

보면 각 스코어에 exp값을 취한다음, 빨간색을 다 더한 값188.68을 각각 나눠주면 초록색 값이 나온다

여기서 -log취한 값은 보라색 0.89값만큼 안좋다라는 뜻

![스크린샷 2023-03-07 오후 2.45.03.png](CS231n%20Lec3%20Loss%20Function%20and%20Optimization%2063f0a3e880ac4097abd6e7c95e9dd87d/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.45.03.png)

svm hinge loss와 softmax의 차이

그렇다면 최적의 w를 찾는 과정 optimization에 대하여…

산속에서 눈을 감고 골짜기를 내려가는 거 Loss가 0인 지점을 찾아가는 것

방법 중 하나는 random search

그냥 랜덤하게 찾는 것 쓰지말자 그냥…

많이 사용하는 경사 하강법(gradient descent)라고 한다

![스크린샷 2023-03-07 오후 2.47.36.png](CS231n%20Lec3%20Loss%20Function%20and%20Optimization%2063f0a3e880ac4097abd6e7c95e9dd87d/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.47.36.png)

미분이다 1차원이면 그냥 미분 다차원이면 편미분된 벡터의 값으로

이 위의 방법 수식으로 하나하나 계산해서 하는 방법은 numercial방법 수치적 방법이다

![스크린샷 2023-03-07 오후 2.48.34.png](CS231n%20Lec3%20Loss%20Function%20and%20Optimization%2063f0a3e880ac4097abd6e7c95e9dd87d/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.48.34.png)

위는 w에 경사하강법을 하는 과정 경사를 구한 값이-2.5다 이거의 기울기는?

![스크린샷 2023-03-07 오후 2.49.04.png](CS231n%20Lec3%20Loss%20Function%20and%20Optimization%2063f0a3e880ac4097abd6e7c95e9dd87d/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.49.04.png)

0.6이 기울기이다

이런식으로 밑에꺼도 하나하나하는게 수치적 방법 >>오래걸림

그래서 chain rule과 같은 analytic gradient(해석적 방법)을 사용하는게 좋다(미분)

요약하자면 numerical gradinet는 정확하지 않고 느리지만 간편(오류가 덜난다)

analytic gradient는 정확하고 빠르지만 에러 가능성 있다

디버깅 및 점검 시는 numerical을 사용하기도 하는데 이거를 gradient check라고 함

![스크린샷 2023-03-07 오후 2.52.27.png](CS231n%20Lec3%20Loss%20Function%20and%20Optimization%2063f0a3e880ac4097abd6e7c95e9dd87d/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.52.27.png)

위는 경사하강법

-를 붙이는 거를 볼 수 있는데 기울기가 음의 방향이면 0인 지점으로 가려면 +방향으로 가야하고 양의 기울기면 -방향으로 가야하기 때문에 -를 붙이는 거다

step_size는 lr(learning rate)다

여기서 개수가 많으면 복잡해지고 느리다

그래서 stochastic gradient descent(SGD)를 많이 사용한다

>>minibatch를 둘어 임의로 몇개씩 잘라서 계산

이거는 다른 블로그의 요약글을 가져왓다

Summary

![https://velog.velcdn.com/images%2Fcha-suyeon%2Fpost%2F7b5ea163-dd3c-4ed9-a5a9-74e536656117%2Fimage.png](https://velog.velcdn.com/images%2Fcha-suyeon%2Fpost%2F7b5ea163-dd3c-4ed9-a5a9-74e536656117%2Fimage.png)

이 이미지를 통해 지금까지 배운 내용의 흐름을 살펴보면 좋겠습니다.

(*x*,*y*)라는 고정된 데이터 쌍이 있을 때, 처음에 무작위로 뽑은 parameter 값으로 바뀌어 나갑니다.

왼쪽에서 오른쪽으로 이동하면서 score function은 각 class의 score를 계산하고, 그 값이 f 벡터에 저장됩니다.

loss function은 `data loss`와 `regularization loss`로 나뉘어져 있습니다. Gradient descent 과정에서 parameter로 미분한 gradient를 계산하고 이를 이용해 parameter를 업데이트합니다.

정리를 해보겠습니다.

- loss function은 산 꼭대기에서 아래로 내려가는 것으로 최적화 과정을 설명했습니다. 특히 SVM loss 의 경우

![https://velog.velcdn.com/images%2Fcha-suyeon%2Fpost%2F6041f982-88e1-48ae-ba30-f3744fc13c14%2Fimage.png](https://velog.velcdn.com/images%2Fcha-suyeon%2Fpost%2F6041f982-88e1-48ae-ba30-f3744fc13c14%2Fimage.png)

loss function은 선형의 모양으로 가장 좋은 parameter 값인 파란색으로 이동해야 하는 경우였습니다.

- loss function을 optimize한다는 것은 무작위로 시작해서 반복하며 더 나은쪽으로 이동한다는 핵심 개념에서 시작되었습니다.
- gradient(기울기)는 그 함수값이 감소하는 가장 빠른 방향이었습니다. 이것을 유한 차분(finite difference, 즉 미분할 때 h의 값이 유한하다는 의미)를 이용하여 단순 무식하게 수치적으로 어림잡아 계산하는 방법도 살펴 보았습니다.
    - 강의에서는 이러한 수치적 미분보다 해석적 미분이 더 좋다고 언급합니다.
- parameter *w*를 업데이트할 때, 한 번에 얼마나 움직여야 하는지를 결정하는 것이 `step size(learning rate, lr)`이었습니다. 학습 속도에 영향을 주는 hyper parameter입니다.
    - 이 값이 너무 낮으면 너무 느려지고, 너무 높으면 빨라지지만 위험한 점이 있다. 이것에 대해선 또 다음 강의에 다룬다고 합니다.
- 수치적 미분과 해석적 미분의 방법
    - 수치적 gradinet: 단순하지만 근사값이고 비효율적임
    - 해석적 gradient: 정확하고 빠르지만 손으로 계산해서 실수할 수 있음
    - 실제 응용에서는 해석적인 gradient을 씁니다. 또한, 둘 다 구한 다음 비교해보고, 틀린 경우 고치는 gradient check 과정을 갖습니다.